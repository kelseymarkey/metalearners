{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from econml.grf import RegressionForest\n",
    "from sklearn import clone\n",
    "import os, pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class t_learner:\n",
    "\n",
    "    '''\n",
    "    From Rosenberg Slides:\n",
    "        µ^0(x) = E[Y (0) | X = x]\n",
    "        µ^1(x) = E[Y (1) | X = x]\n",
    "        τˆT (x) = µˆ1(x) − µˆ0(x)\n",
    "\n",
    "    authors: Alene Rhea and Tamar Novetsky, April 1 2021\n",
    "    '''\n",
    "\n",
    "    def __init__(self, mu0_base, mu1_base):\n",
    "        # Make copies of initialized base learners\n",
    "        self.mu0_base = clone(mu0_base, safe=False)\n",
    "        self.mu1_base = clone(mu1_base, safe=False)\n",
    "\n",
    "    def fit(self, X, W, y):\n",
    "        # Call fit methods on each base learner\n",
    "        self.mu0_base.fit(X[W==0], y[W==0])\n",
    "        self.mu1_base.fit(X[W==1], y[W==1])\n",
    "\n",
    "    def predict(self, X):\n",
    "        y1_preds = self.mu1_base.predict(X)\n",
    "        y0_preds = self.mu0_base.predict(X)\n",
    "        tau_preds = y1_preds - y0_preds\n",
    "        return tau_preds.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class s_learner:\n",
    "\n",
    "    '''\n",
    "    From Rosenberg Slides:\n",
    "        µ^(x,w) = E[Y | X = x, W = w]\n",
    "        τˆS (x) = µˆ(x,1) − µˆ(x,0)\n",
    "\n",
    "    authors: Kelsey Markey and Lauren D'Arinzo, April 4 2021\n",
    "    '''\n",
    "\n",
    "    def __init__(self, mu_base):\n",
    "        # Make copies of initialized base learner\n",
    "        self.mu_base = clone(mu_base, safe=False)\n",
    "\n",
    "    def fit(self, X_W, y):\n",
    "        # Call fit method\n",
    "        self.mu_base.fit(X_W, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_W_1 = X.copy(deep=True)\n",
    "        X_W_1[\"W\"] = pd.Series(np.ones(len(X_W_1)))\n",
    "        y1_preds = self.mu_base.predict(X_W_1)\n",
    "\n",
    "        X_W_0 = X.copy(deep=True)\n",
    "        X_W_0[\"W\"] = pd.Series(np.zeros(len(X_W_0)))\n",
    "        y0_preds = self.mu_base.predict(X_W_0)\n",
    "\n",
    "        tau_preds = y1_preds - y0_preds\n",
    "        return tau_preds.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class x_learner:\n",
    "\n",
    "    '''\n",
    "    From Rosenberg Slides:\n",
    "        µ^0(x) = E[Y (0) | X = x]\n",
    "        µ^1(x) = E[Y (1) | X = x]\n",
    "        τˆx (x) = g(x)t_0ˆ(x) − (1-g(x))t_1ˆ(x)\n",
    "\n",
    "    authors: Kelsey Markey and Lauren D'Arinzo, April 4 2021\n",
    "    '''\n",
    "\n",
    "    def __init__(self, mu0_base, mu1_base, tau0_base, tau1_base):\n",
    "        # Make copies of initialized base learner\n",
    "        self.mu0_base = clone(mu0_base, safe=False)\n",
    "        self.mu1_base = clone(mu1_base, safe=False)\n",
    "        self.tau0_base = clone(tau0_base, safe=False)\n",
    "        self.tau1_base = clone(tau1_base, safe=False)\n",
    "\n",
    "    def fit(self, X, W, y):\n",
    "        # Call fit method\n",
    "        self.mu0_base.fit(X[W==0], y[W==0])\n",
    "        self.mu1_base.fit(X[W==1], y[W==1])\n",
    "    \n",
    "        #Impute y0 for treated group using mu0\n",
    "        y0_treat=self.mu0_base.predict(X[W==1]).flatten()\n",
    "        imputed_TE_treatment = y[W==1] - y0_treat\n",
    "\n",
    "        #Impute y1 for control group using mu1\n",
    "        y1_control=self.mu1_base.predict(X[W==0]).flatten()\n",
    "        imputed_TE_control = y1_control - y[W==0] \n",
    "\n",
    "        #Fit tau0: CATE estimate fit to the control group\n",
    "        self.tau0_base.fit(X[W==0], imputed_TE_control)\n",
    "\n",
    "        #Fit tau1: CATE estimate fit to the treatment group\n",
    "        self.tau1_base.fit(X[W==1], imputed_TE_treatment)\n",
    "\n",
    "    def predict(self, X, g):\n",
    "        '''\n",
    "        g : weight vector that should be length of the test set\n",
    "        '''\n",
    "        tau0_preds = self.tau0_base.predict(X).flatten()\n",
    "        tau1_preds = self.tau1_base.predict(X).flatten()\n",
    "        tau_preds = (g.T * tau0_preds) + ((1-g).T*tau1_preds)\n",
    "        return tau_preds.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_get_mse_t(train, test, mu0_base, mu1_base):\n",
    "    '''\n",
    "    mu0_base: base learner that has already been initialized\n",
    "    mu1_base: base learner that has already been initialized\n",
    "    '''\n",
    "    #data preprocessing\n",
    "    X_train = train.drop(columns=['treatment', 'Y', 'tau', 'pscore'])\n",
    "    y_train = train['Y']\n",
    "    W_train = train['treatment']\n",
    "    X_test = test.drop(columns=['treatment', 'Y', 'tau', 'pscore'])\n",
    "\n",
    "    #initialize metalearner\n",
    "    T = t_learner(mu0_base=mu0_base, mu1_base=mu1_base)\n",
    "    T.fit(X=X_train, W=W_train, y=y_train)\n",
    "    \n",
    "    # Predict test-set CATEs\n",
    "    tau_preds = T.predict(X=X_test)\n",
    "\n",
    "    # Calculate MSE on test set\n",
    "    mse = np.mean((tau_preds - test.tau)**2)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_get_mse_s(train, test, mu_base):\n",
    "    '''\n",
    "    mu: base learner that has already been initialized\n",
    "    '''\n",
    "    #data preprocessing\n",
    "    X_train = train.drop(columns=['treatment', 'Y', 'tau', 'pscore'])\n",
    "    y_train = train['Y']\n",
    "    W_train = train['treatment']\n",
    "    X_test = test.drop(columns=['treatment', 'Y', 'tau', 'pscore'])\n",
    "\n",
    "    #initialize metalearner\n",
    "    S = s_learner(mu_base=mu_base)\n",
    "    \n",
    "    #fit S-learner\n",
    "    X_W = pd.concat([X_train, W_train], axis=1)\n",
    "    S.fit(X_W=X_W, y=y_train)\n",
    "    \n",
    "    # Predict test-set CATEs\n",
    "    tau_preds = S.predict(X=X_test)\n",
    "\n",
    "    # Calculate MSE on test set\n",
    "    mse = np.mean((tau_preds - test.tau)**2)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_get_mse_x(train, test, mu0_base, mu1_base, tau0_base, tau1_base):\n",
    "    '''\n",
    "    mu0_base: base learner that has already been initialized\n",
    "    mu1_base: base learner that has already been initialized\n",
    "    tau0_base: base learner that has already been initialized\n",
    "    tau1_base: base learner that has already been initialized\n",
    "    '''\n",
    "    #data preprocessing\n",
    "    X_train = train.drop(columns=['treatment', 'Y', 'tau', 'pscore'])\n",
    "    y_train = train['Y']\n",
    "    W_train = train['treatment']\n",
    "    X_test = test.drop(columns=['treatment', 'Y', 'tau', 'pscore'])\n",
    "    g_true = test['pscore'].to_numpy()\n",
    "    \n",
    "    #fit g using training data\n",
    "    g_fit = LogisticRegression(fit_intercept=True, max_iter=2000).fit(\n",
    "       X=X_train, y=W_train)\n",
    "    #predict on test set\n",
    "    g_pred = g_fit.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # initialize metalearner\n",
    "    X_learner = x_learner(mu0_base=mu0_base, mu1_base=mu1_base, tau0_base=tau0_base, tau1_base=tau1_base)\n",
    "    # Fit treatment and response estimators mu0 and  mu1\n",
    "    X_learner.fit(X=X_train, W=W_train, y=y_train)\n",
    "    \n",
    "    # Predict test-set CATEs using true and predicted propensities\n",
    "    tau_preds_gtrue = X_learner.predict(X=X_test, g=g_true)\n",
    "    tau_preds_gpred = X_learner.predict(X=X_test, g=g_pred)\n",
    "    \n",
    "    # Calculate RMSE on test set for X-Learners with true and predicted propensities\n",
    "    mse_true = np.mean((tau_preds_gtrue - test.tau)**2)\n",
    "    mse_pred = np.mean((tau_preds_gpred - test.tau)**2)\n",
    "    \n",
    "    return mse_true, mse_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Set root directory\n",
    "    # base_repo_dir = pathlib.Path(os.path.realpath(__file__)).parents[0]\n",
    "    base_repo_dir = os.getcwd()\n",
    "    \n",
    "    # read in tuned hyperparameter files\n",
    "    rf_t = json.load(open(base_repo_dir + '/configurations/hyperparameters/' + 'rf_t.json'))\n",
    "    rf_s = json.load(open(base_repo_dir + '/configurations/hyperparameters/' + 'rf_s.json'))\n",
    "    rf_x = json.load(open(base_repo_dir + '/configurations/hyperparameters/' + 'rf_x.json'))\n",
    "    \n",
    "    rf_params = {'T': rf_t, 'S': rf_s, 'X': rf_x}\n",
    "    \n",
    "    # read in base learner model types for each metalearner\n",
    "    meta_base_dict = json.load(open(base_repo_dir + '/configurations/base_learners/' + 'base_learners.json'))\n",
    "    \n",
    "    for train_size in [5000, 10000]: #, 20000, 100000, 300000\n",
    "        print('---------------------------')\n",
    "        print('Training set size:', train_size)\n",
    "        for sim in ['simA', 'simB', 'simC', 'simD', 'simE', 'simF']:\n",
    "            print('---------------------------')\n",
    "            print('Starting '+ sim)\n",
    "            for i in range(3):\n",
    "                print('')\n",
    "                train = pd.read_parquet(base_repo_dir + '/data/' + str(train_size) + '/' + sim + \n",
    "                                        '/samp'+str(i+1)+'_train.parquet')\n",
    "                test = pd.read_parquet(base_repo_dir + '/data/' + str(train_size) + '/' + sim +  \n",
    "                                       '/samp'+str(i+1)+'_test.parquet')\n",
    "                for metalearner in meta_base_dict.keys():\n",
    "                    if metalearner == 'T':\n",
    "                    # below logic needs to be generalized for other metalearners\n",
    "                        for base_learner_dict in meta_base_dict[metalearner]:\n",
    "                            print(sim+'/' +'sample_'+str(i+1)+'/'+metalearner+'-learner:')\n",
    "                            if base_learner_dict['mu_0'] == 'rf':\n",
    "                                mu0_hyperparams = rf_params[metalearner]['mu_0'][sim]\n",
    "                                # uncomment out all of these lines once hyperparameter jsons updated from tuning\n",
    "                                # mu0_base = RegressionForest(honest=True, random_state=42, **mu0_hyperparams)\n",
    "                                mu0_base = RegressionForest(honest=True, random_state=42)\n",
    "                            if base_learner_dict['mu_1'] == 'rf':\n",
    "                                mu1_hyperparams = rf_params[metalearner]['mu_1'][sim]\n",
    "                                #mu1_base = RegressionForest(honest=True, random_state=42, **mu1_hyperparams)\n",
    "                                mu1_base = RegressionForest(honest=True, random_state=42)\n",
    "                            mse = fit_get_mse_t(train, test, mu0_base, mu1_base)\n",
    "                            print('     MSE=', mse)\n",
    "\n",
    "                    if metalearner == 'S':\n",
    "                        for base_learner_dict in meta_base_dict[metalearner]:\n",
    "                            print(sim+'/' +'sample_'+str(i+1)+'/'+ metalearner+'-learner:')\n",
    "                            if base_learner_dict['mu'] == 'rf':\n",
    "                                mu_hyperparams = rf_params[metalearner]['mu'][sim]\n",
    "                                # uncomment out all of these lines once hyperparameter jsons updated from tuning\n",
    "                                # mu_base = RegressionForest(honest=True, random_state=42, **mu_hyperparams)\n",
    "                                mu_base = RegressionForest(honest=True, random_state=42)\n",
    "                            mse = fit_get_mse_s(train, test, mu_base)\n",
    "                            print('     MSE=', mse)\n",
    "                            \n",
    "                    if metalearner == 'X':\n",
    "                        for base_learner_dict in meta_base_dict[metalearner]:\n",
    "                            print(sim+'/' +'sample_'+str(i+1)+'/'+ metalearner+'-learner:')\n",
    "                            if base_learner_dict['mu_0'] == 'rf':\n",
    "                                mu0_hyperparams = rf_params[metalearner]['mu_0'][sim]\n",
    "                                # uncomment out all of these lines once hyperparameter jsons updated from tuning\n",
    "                                # mu0_base = RegressionForest(honest=True, random_state=42, **mu0_hyperparams)\n",
    "                                mu0_base = RegressionForest(honest=True, random_state=42)\n",
    "                            if base_learner_dict['mu_1'] == 'rf':\n",
    "                                mu1_hyperparams = rf_params[metalearner]['mu_1'][sim]\n",
    "                                # mu1_base = RegressionForest(honest=True, random_state=42, **mu1_hyperparams)\n",
    "                                mu1_base = RegressionForest(honest=True, random_state=42)\n",
    "                            if base_learner_dict['tau_0'] == 'rf':\n",
    "                                tau0_hyperparams = rf_params[metalearner]['tau_0'][sim]\n",
    "                                # tau0_base = RegressionForest(honest=True, random_state=42, **tau0_hyperparams)\n",
    "                                tau0_base = RegressionForest(honest=True, random_state=42)\n",
    "                            if base_learner_dict['tau_1'] == 'rf':\n",
    "                                tau1_hyperparams = rf_params[metalearner]['tau_1'][sim]\n",
    "                                # tau1_base = RegressionForest(honest=True, random_state=42, **tau1_hyperparams)\n",
    "                                tau1_base = RegressionForest(honest=True, random_state=42)\n",
    "                            mse_true, mse_pred = fit_get_mse_x(train, test, mu0_base, mu1_base, tau0_base, tau1_base)\n",
    "                            print('     MSE (true pscore)=', mse_true)\n",
    "                            print('     MSE (estimated pscore)=', mse_pred)\n",
    "                                \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Training set size: 5000\n",
      "---------------------------\n",
      "Starting simA\n",
      "\n",
      "simA/sample_1/T-learner:\n",
      "     MSE= 70.5903458821425\n",
      "simA/sample_1/S-learner:\n",
      "     MSE= 29.504\n",
      "simA/sample_1/X-learner:\n",
      "     MSE (true pscore)= 15.528076958296719\n",
      "     MSE (estimated pscore)= 15.525902295021718\n",
      "\n",
      "simA/sample_2/T-learner:\n",
      "     MSE= 128.86942413945602\n",
      "simA/sample_2/S-learner:\n",
      "     MSE= 29.36192\n",
      "simA/sample_2/X-learner:\n",
      "     MSE (true pscore)= 15.889626490550594\n",
      "     MSE (estimated pscore)= 15.941984866240778\n",
      "\n",
      "simA/sample_3/T-learner:\n",
      "     MSE= 81.8478094129798\n",
      "simA/sample_3/S-learner:\n",
      "     MSE= 29.50784\n",
      "simA/sample_3/X-learner:\n",
      "     MSE (true pscore)= 12.916036870520832\n",
      "     MSE (estimated pscore)= 12.918035011769998\n",
      "---------------------------\n",
      "Starting simB\n",
      "\n",
      "simB/sample_1/T-learner:\n",
      "     MSE= 6829.868912129078\n",
      "simB/sample_1/S-learner:\n",
      "     MSE= 3643.8783749853433\n",
      "simB/sample_1/X-learner:\n",
      "     MSE (true pscore)= 4181.431174191899\n",
      "     MSE (estimated pscore)= 4171.236981074213\n",
      "\n",
      "simB/sample_2/T-learner:\n",
      "     MSE= 5351.6783386072775\n",
      "simB/sample_2/S-learner:\n",
      "     MSE= 2220.897901190617\n",
      "simB/sample_2/X-learner:\n",
      "     MSE (true pscore)= 3519.5777076116037\n",
      "     MSE (estimated pscore)= 3523.952117794269\n",
      "\n",
      "simB/sample_3/T-learner:\n",
      "     MSE= 2941.2573594159294\n",
      "simB/sample_3/S-learner:\n",
      "     MSE= 1632.9391185531488\n",
      "simB/sample_3/X-learner:\n",
      "     MSE (true pscore)= 1800.2665578666729\n",
      "     MSE (estimated pscore)= 1802.158669916378\n",
      "---------------------------\n",
      "Starting simC\n",
      "\n",
      "simC/sample_1/T-learner:\n",
      "     MSE= 0.044908067239896925\n",
      "simC/sample_1/S-learner:\n",
      "     MSE= 0.04713877901167583\n",
      "simC/sample_1/X-learner:\n",
      "     MSE (true pscore)= 0.05243544301732499\n",
      "     MSE (estimated pscore)= 0.05260527224114883\n",
      "\n",
      "simC/sample_2/T-learner:\n",
      "     MSE= 0.045876581434470015\n",
      "simC/sample_2/S-learner:\n",
      "     MSE= 0.06091496169209664\n",
      "simC/sample_2/X-learner:\n",
      "     MSE (true pscore)= 0.0424547218295933\n",
      "     MSE (estimated pscore)= 0.041530817764165825\n",
      "\n",
      "simC/sample_3/T-learner:\n",
      "     MSE= 0.04114811994813679\n",
      "simC/sample_3/S-learner:\n",
      "     MSE= 0.04046685909336563\n",
      "simC/sample_3/X-learner:\n",
      "     MSE (true pscore)= 0.04641332955117469\n",
      "     MSE (estimated pscore)= 0.046924254063299496\n",
      "---------------------------\n",
      "Starting simD\n",
      "\n",
      "simD/sample_1/T-learner:\n",
      "     MSE= 0.02710383702801818\n",
      "simD/sample_1/S-learner:\n",
      "     MSE= 0.00011068402722732429\n",
      "simD/sample_1/X-learner:\n",
      "     MSE (true pscore)= 0.0023886002901608553\n",
      "     MSE (estimated pscore)= 0.0025904930878011224\n",
      "\n",
      "simD/sample_2/T-learner:\n",
      "     MSE= 0.011837943488447385\n",
      "simD/sample_2/S-learner:\n",
      "     MSE= 6.062221695571212e-05\n",
      "simD/sample_2/X-learner:\n",
      "     MSE (true pscore)= 0.0020200297780572168\n",
      "     MSE (estimated pscore)= 0.002072411267507624\n",
      "\n",
      "simD/sample_3/T-learner:\n",
      "     MSE= 0.02466163401136765\n",
      "simD/sample_3/S-learner:\n",
      "     MSE= 0.0001991740582602755\n",
      "simD/sample_3/X-learner:\n",
      "     MSE (true pscore)= 0.0019306443889642497\n",
      "     MSE (estimated pscore)= 0.001889974044580747\n",
      "---------------------------\n",
      "Starting simE\n",
      "\n",
      "simE/sample_1/T-learner:\n",
      "     MSE= 0.046200159761291916\n",
      "simE/sample_1/S-learner:\n",
      "     MSE= 0.0467233477612666\n",
      "simE/sample_1/X-learner:\n",
      "     MSE (true pscore)= 0.016693348861002395\n",
      "     MSE (estimated pscore)= 0.016817629361673542\n",
      "\n",
      "simE/sample_2/T-learner:\n",
      "     MSE= 0.04671808974465152\n",
      "simE/sample_2/S-learner:\n",
      "     MSE= 0.037279312601010625\n",
      "simE/sample_2/X-learner:\n",
      "     MSE (true pscore)= 0.029821708274018196\n",
      "     MSE (estimated pscore)= 0.02986568192926481\n",
      "\n",
      "simE/sample_3/T-learner:\n",
      "     MSE= 0.048407080332889235\n",
      "simE/sample_3/S-learner:\n",
      "     MSE= 0.051096775658179834\n",
      "simE/sample_3/X-learner:\n",
      "     MSE (true pscore)= 0.02399337491582576\n",
      "     MSE (estimated pscore)= 0.02412877773564822\n",
      "---------------------------\n",
      "Starting simF\n",
      "\n",
      "simF/sample_1/T-learner:\n",
      "     MSE= 1.6560708428009143\n",
      "simF/sample_1/S-learner:\n",
      "     MSE= 1.6566698442424281\n",
      "simF/sample_1/X-learner:\n",
      "     MSE (true pscore)= 1.6212357410933682\n",
      "     MSE (estimated pscore)= 1.6174530490667067\n",
      "\n",
      "simF/sample_2/T-learner:\n",
      "     MSE= 1.6047720094057316\n",
      "simF/sample_2/S-learner:\n",
      "     MSE= 1.5675891801413635\n",
      "simF/sample_2/X-learner:\n",
      "     MSE (true pscore)= 1.6397800658233563\n",
      "     MSE (estimated pscore)= 1.6380954159282284\n",
      "\n",
      "simF/sample_3/T-learner:\n",
      "     MSE= 1.7261568664681146\n",
      "simF/sample_3/S-learner:\n",
      "     MSE= 1.7416168409890378\n",
      "simF/sample_3/X-learner:\n",
      "     MSE (true pscore)= 1.6649337008166512\n",
      "     MSE (estimated pscore)= 1.671472849852936\n",
      "---------------------------\n",
      "Training set size: 10000\n",
      "---------------------------\n",
      "Starting simA\n",
      "\n",
      "simA/sample_1/T-learner:\n",
      "     MSE= 36.87967741219914\n",
      "simA/sample_1/S-learner:\n",
      "     MSE= 29.30432\n",
      "simA/sample_1/X-learner:\n",
      "     MSE (true pscore)= 14.14992696356146\n",
      "     MSE (estimated pscore)= 14.144821092284001\n",
      "\n",
      "simA/sample_2/T-learner:\n",
      "     MSE= 46.72604568547924\n",
      "simA/sample_2/S-learner:\n",
      "     MSE= 29.56608\n",
      "simA/sample_2/X-learner:\n",
      "     MSE (true pscore)= 11.925574932536753\n",
      "     MSE (estimated pscore)= 11.927049439298319\n",
      "\n",
      "simA/sample_3/T-learner:\n",
      "     MSE= 56.18248926636027\n",
      "simA/sample_3/S-learner:\n",
      "     MSE= 29.50464\n",
      "simA/sample_3/X-learner:\n",
      "     MSE (true pscore)= 4.5923525213123755\n",
      "     MSE (estimated pscore)= 4.638286859753566\n",
      "---------------------------\n",
      "Starting simB\n",
      "\n",
      "simB/sample_1/T-learner:\n",
      "     MSE= 4199.666673896808\n",
      "simB/sample_1/S-learner:\n",
      "     MSE= 1942.7484966666332\n",
      "simB/sample_1/X-learner:\n",
      "     MSE (true pscore)= 3492.823873001852\n",
      "     MSE (estimated pscore)= 3493.3805674805003\n",
      "\n",
      "simB/sample_2/T-learner:\n",
      "     MSE= 2605.9185862669347\n",
      "simB/sample_2/S-learner:\n",
      "     MSE= 1881.2273170041228\n",
      "simB/sample_2/X-learner:\n",
      "     MSE (true pscore)= 2323.706637399654\n",
      "     MSE (estimated pscore)= 2319.819628523282\n",
      "\n",
      "simB/sample_3/T-learner:\n",
      "     MSE= 3886.6858822349677\n",
      "simB/sample_3/S-learner:\n",
      "     MSE= 2752.2524025446337\n",
      "simB/sample_3/X-learner:\n",
      "     MSE (true pscore)= 3931.372861452063\n",
      "     MSE (estimated pscore)= 3927.046468010635\n",
      "---------------------------\n",
      "Starting simC\n",
      "\n",
      "simC/sample_1/T-learner:\n",
      "     MSE= 0.03566673320253051\n",
      "simC/sample_1/S-learner:\n",
      "     MSE= 0.03680297665555711\n",
      "simC/sample_1/X-learner:\n",
      "     MSE (true pscore)= 0.03536900619825309\n",
      "     MSE (estimated pscore)= 0.03543177815900654\n",
      "\n",
      "simC/sample_2/T-learner:\n",
      "     MSE= 0.03471789783204059\n",
      "simC/sample_2/S-learner:\n",
      "     MSE= 0.03703625984446166\n",
      "simC/sample_2/X-learner:\n",
      "     MSE (true pscore)= 0.03538693525909695\n",
      "     MSE (estimated pscore)= 0.035359985282309256\n",
      "\n",
      "simC/sample_3/T-learner:\n",
      "     MSE= 0.019704672749761697\n",
      "simC/sample_3/S-learner:\n",
      "     MSE= 0.019586377542611933\n",
      "simC/sample_3/X-learner:\n",
      "     MSE (true pscore)= 0.021085758044923287\n",
      "     MSE (estimated pscore)= 0.021079434878045727\n",
      "---------------------------\n",
      "Starting simD\n",
      "\n",
      "simD/sample_1/T-learner:\n",
      "     MSE= 0.009441091270430036\n",
      "simD/sample_1/S-learner:\n",
      "     MSE= 0.00011259274588595792\n",
      "simD/sample_1/X-learner:\n",
      "     MSE (true pscore)= 0.001353576105562973\n",
      "     MSE (estimated pscore)= 0.0013721713850944968\n",
      "\n",
      "simD/sample_2/T-learner:\n",
      "     MSE= 0.008784041105930137\n",
      "simD/sample_2/S-learner:\n",
      "     MSE= 8.696089164866259e-05\n",
      "simD/sample_2/X-learner:\n",
      "     MSE (true pscore)= 0.0011044920288220397\n",
      "     MSE (estimated pscore)= 0.0011074603677747575\n",
      "\n",
      "simD/sample_3/T-learner:\n",
      "     MSE= 0.013813431500397766\n",
      "simD/sample_3/S-learner:\n",
      "     MSE= 9.30605221396012e-05\n",
      "simD/sample_3/X-learner:\n",
      "     MSE (true pscore)= 0.0015275259098944183\n",
      "     MSE (estimated pscore)= 0.0015511143646060699\n",
      "---------------------------\n",
      "Starting simE\n",
      "\n",
      "simE/sample_1/T-learner:\n",
      "     MSE= 0.02591769372966545\n",
      "simE/sample_1/S-learner:\n",
      "     MSE= 0.024740947938049717\n",
      "simE/sample_1/X-learner:\n",
      "     MSE (true pscore)= 0.0165383543838599\n",
      "     MSE (estimated pscore)= 0.016628185575825752\n",
      "\n",
      "simE/sample_2/T-learner:\n",
      "     MSE= 0.01929158176057399\n",
      "simE/sample_2/S-learner:\n",
      "     MSE= 0.02064871980618873\n",
      "simE/sample_2/X-learner:\n",
      "     MSE (true pscore)= 0.011407666261021944\n",
      "     MSE (estimated pscore)= 0.011219358178489545\n",
      "\n",
      "simE/sample_3/T-learner:\n",
      "     MSE= 0.025843776740911158\n",
      "simE/sample_3/S-learner:\n",
      "     MSE= 0.02329644732597454\n",
      "simE/sample_3/X-learner:\n",
      "     MSE (true pscore)= 0.011395036626970903\n",
      "     MSE (estimated pscore)= 0.011225233499865966\n",
      "---------------------------\n",
      "Starting simF\n",
      "\n",
      "simF/sample_1/T-learner:\n",
      "     MSE= 1.560736272953663\n",
      "simF/sample_1/S-learner:\n",
      "     MSE= 1.5811969092741547\n",
      "simF/sample_1/X-learner:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     MSE (true pscore)= 1.5644026514615719\n",
      "     MSE (estimated pscore)= 1.5645664582262708\n",
      "\n",
      "simF/sample_2/T-learner:\n",
      "     MSE= 1.6138286814763119\n",
      "simF/sample_2/S-learner:\n",
      "     MSE= 1.6116599536597596\n",
      "simF/sample_2/X-learner:\n",
      "     MSE (true pscore)= 1.565543701065179\n",
      "     MSE (estimated pscore)= 1.566557722952503\n",
      "\n",
      "simF/sample_3/T-learner:\n",
      "     MSE= 1.6886097955730144\n",
      "simF/sample_3/S-learner:\n",
      "     MSE= 1.682713589100822\n",
      "simF/sample_3/X-learner:\n",
      "     MSE (true pscore)= 1.6374343785448022\n",
      "     MSE (estimated pscore)= 1.640377357418064\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
